{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark ran\n"
     ]
    }
   ],
   "source": [
    "from os import chdir\n",
    "from itertools import compress\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, explode, col, lit, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, CountVectorizer\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "import json\n",
    "import re\n",
    "print(\"spark ran\")\n",
    "\n",
    "chdir(\"/home/centos/Desktop/ingest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List length: 524\n",
      "['longan', 'calalu', 'mutton', 'langoustine', 'paprika', 'plaice', 'coriander', 'marron', 'basil', 'noisette', 'buttermilk', 'cranberry', 'liverwurst', 'tansy', 'veal', 'miso', 'shaddock', 'cockle', 'cashew', 'mousetrap', 'cumin', 'round', 'chicory', 'pineapple', 'margarine', 'cherry', 'ham', 'dolcelatte', 'lamb', 'durion', 'grapefruit', 'game', 'bass', 'butter', 'tayberry', 'skirt', 'haslet', 'choko', 'halibut', 'pomegranate', 'jarlsberg', 'cardamom', 'courgette', 'chervil', 'mackerel', 'forehock', 'sardine', 'taleggio', 'saffron', 'bakeapple', 'shoulder', 'greens', 'queenie', 'gorgonzola', 'salmon', 'lemon', 'anchovy', 'prune', 'pistachio', 'chayote', 'terakihi', 'nut', 'teraglin', 'cervelat', 'pimiento', 'clove', 'snook', 'sapota', 'gooseberry', 'bonito', 'clappy-doo', 'cutlet', 'squid', 'chop', 'pollack', 'octopus', 'bramble', 'pike', 'cumquat', 'kahawai', 'chard', 'yam', 'broccoli', 'romano', 'pomelo', 'brill', 'sprat', 'huss', 'chestnut', 'edam', 'apple', 'tamarillo', 'loganberry', 'watermelon', 'saddle', 'adjigo', 'loquat', 'cheshire', 'aubergine', 'roach', 'plantain', 'orange', 'elderberry', 'ling', 'allspice', 'granadilla', 'eggplant', 'rump', 'chateaubriand', 'sausage', 'turnip', 'calamondin', 'offal', 'aniseed', 'pigeon', 'tongue', 'gherkin', 'apricot', 'groundnut', 'mozzarella', 'muskmelon', 'cantal', 'marjoram', 'oat', 'quince', 'medlar', 'sweetbread', 'turbot', 'nutmeg', 'cinnamon', 'pea', 'whiting', 'flour', 'sweetsop', 'rack', 'pastrami', 'tarakihi', 'carambola', 'escalope', 'hackberry', 'sugar', 'macadamia', 'topside', 'pork', 'mandarin', 'kail', 'dill', 'scollop', 'salmonberry', 'silverside', 'wasabi', 'wahoo', 'mortadella', 'thyme', 'meat', 'calabrese', 'salt', 'caboc', 'lancashire', 'chilli', 'casaba', 'tangerine', 'mycella', 'spinach', 'cantaloupe', 'goosegog', 'tangelo', 'grape', 'mullet', 'cardoon', 'nashi', 'redcurrant', 'sockeye', 'pecan', 'tunny', 'rosemary', 'peanut', 'pilchard', 'chorizo', 'turkey', 'cucumber', 'ackee', 'jaggery', 'kidney', 'yabbie', 'knockwurst', 'pawpaw', 'celery', 'bratwurst', 'radish', 'tarragon', 'persimmon', 'papaya', 'canella', 'horseradish', 'undercut', 'flounder', 'fig', 'clabby-doo', 'sorrel', 'lime', 'salami', 'strawberry', 'muenster', 'asafetida', 'cassava', 'saithe', 'knackwurst', 'banana', 'greengage', 'saveloy', 'shrimp', 'boxberry', 'goose', 'frisee', 'leek', 'fillet', 'mulloway', 'oyster', 'orache', 'snoek', 'kale', 'liver', 'jack', 'sild', 'foreshank', 'mango', 'perch', 'tenderloin', 'blackcurrant', 'wensleydale', 'winkle', 'calaloo', 'yabby', 'reblochon', 'sirloin', 'pimento', 'quark', 'hake', 'whitebait', 'cheese', 'dunlop', 'brisket', 'kumquat', 'prawn', 'snowberry', 'oxtail', 'jackfruit', 'boerewors', 'gjetost', 'seafood', 'rocambole', 'star-apple', 'emmental', 'vegetable', 'caerphilly', 'loin', 'leicester', 'chipolata', 'sloe', 'lights', 'provolone', 'asparagus', 'bloater', 'tuna', 'cheddar', 'capers', 'pemmican', 'pepper', 'chive', 'leg', 'cod', 'walnut', 'marrow', 'parmesan', 'salsify', 'berries', 'chempaduk', 'shad', 'ginger', 'nannygai', 'oka', 'berry', 'coconut', 'raisin', 't-bone', 'dab', 'asafoetida', 'ermite', 'limburger', 'naartje', 'youngberry', 'victoria', 'rambutan', 'galangal', 'beef', 'gristle', 'barramundi', 'emmenthal', 'boysenberry', 'shark', 'megrim', 'maize', 'chicken', 'wagyu', 'neufchâtel', 'mangosteen', 'oxtongue', 'cabbage', 'stilton', 'caraway', 'cloudberry', 'babaco', 'crowdie', 'dorado', 'rib', 'sweetie', 'radicchio', 'corn', 'sparerib', 'galingale', 'papaw', 'hogg', 'savory', 'lettuce', 'zander', 'earthnut', 'quandong', 'mace', 'collar', 'scrag', 'crab', 'milk', 'sultana', 'serviceberry', 'chump', 'finocchio', 'witch', 'borage', 'skate', 'shank', 'gigot', 'gammon', 'bream', 'nectarine', 'clam', 'romanesco', 'haddock', 'feta', 'tournedos', 'grayling', 'cauliflower', 'tamarind', 'venison', 'port-salut', 'kipper', 'sapsago', 'fennel', 'endive', 'guava', 'parsnip', 'fontina', 'blackberry', 'oregano', 'almond', 'honey', 'ortanique', 'sole', 'camembert', 'water', 'codling', 'date', 'havarti', 'pear', 'peach', 'eel', 'carrot', 'artichoke', 'mint', 'mussel', 'melon', 'calendula', 'potato', 'pillie', 'zucchini', 'damson', 'raspberry', 'vacherin', 'charqui', 'neep', 'callop', 'hazelnut', 'warran', 'garlic', 'mustard', 'butternut', 'snapper', 'hogget', 'mascarpone', 'pepperoni', 'cress', 'swede', 'scallop', 'carp', 'tripe', 'duck', 'mulberry', 'blueberry', 'citron', 'ugli', 'morwong', 'trout', 'pignut', 'chokecherry', 'prosciutto', 'abalone', 'minneola', 'breast', 'satsuma', 'olive', 'turmeric', 'roquefort', 'pomfret', 'breadfruit', 'durian', 'mince', 'avocado', 'pout', 'herring', 'pipi', 'médaillons', 'chickpea', 'whelk', 'peppercorn', 'clementine', 'chuck', 'pheasant', 'beetroot', 'plum', 'collard', 'ananas', 'beet', 'fruit', 'panocha', 'sage', 'yeast', 'lobster', 'soursop', 'herb', 'celeriac', 'shoyu', 'onion', 'squash', 'brie', 'kohlrabi', 'shallot', 'pecorino', 'tomato', 'gouda', 'saskatoon', 'dewberry', 'ricotta', 'steak', 'egg', 'bacon', 'sprout', 'parsley', 'bayleaf', 'polony', 'pumpkin', 'bell pepper', 'numbles ', 'pine kernel', 'bel paese', 'garam masala', \"parson's nose\", 'szechaun peppercorns', 'lemon grass', 'cassia bark', 'star anise', 'marrow squash', 'spring greens', 'brown sugar', 'cane sugar', 'sea cucumber', 'baking mix', 'fish sauce', 'palm sugar', 'spring onion', 'passion fruit', 'chuck steak', 'salt pork', 'olive oil', 'parma ham', 'winter melon', 'colonial goose', 'gloucester', 'dover sole', 'sour gourd', 'monterey jack', 'star fruit', 'brussels sprout', 'silver beet', 'blood orange', 'bath chap', 'soy sauce', 'black pudding', 'vegetable marrow', 'powdered sugar', 'sunflower seed', \"pope's eye\", 'cold cuts', 'soya sauce', 'sweet potato', 'white sesame', 'black sesame', 'bean sprout', 'red pepper', 'sharon fruit', 'nam pla', 'heart cherry', 'soya bean', 'luncheon meat', '']\n"
     ]
    }
   ],
   "source": [
    "#Creation of filtering words\n",
    "with open(\"/home/centos/Desktop/ingest/Overall_Master.txt\", encoding=\"ISO-8859-1\") as file:\n",
    "    ingredient_set = file.read().splitlines()\n",
    "\n",
    "print(\"List length: \" +str(len(ingredient_set)))\n",
    "print(ingredient_set)\n",
    "ingredient_set = ingredient_set[1:10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#let's try splitting the list into unigram, bi-gram and tri-gram\n",
    "#find out the longest item in list\n",
    "max_length = 0\n",
    "for item in ingredient_list:\n",
    "    temp = item.split(\" \")\n",
    "    count = len(temp)\n",
    "    if (count > max_length):\n",
    "        max_length = count\n",
    "del item, temp, count\n",
    "print(\"Longest length: \" + str(max_length))\n",
    "\n",
    "#Let's split into 4 groups\n",
    "(ingredient_1, ingredient_2, ingredient_3, ingredient_4) = [[], [], [], []]\n",
    "\n",
    "for item in ingredient_list:\n",
    "    temp = item.split(\" \")\n",
    "    check_length = len(temp)\n",
    "    if (check_length == 1):\n",
    "        ingredient_1.append(item)\n",
    "    if (check_length == 2):\n",
    "        ingredient_2.append(item)\n",
    "#     if (check_length == 3):\n",
    "#         ingredient_3.append(item)\n",
    "#     if (check_length == 4):\n",
    "#         ingredient_4.append(item)\n",
    "del temp, item, check_length\n",
    "\n",
    "ingredient_set = []\n",
    "for ing in ingredient_1:\n",
    "    ingredient_set.append(ing)\n",
    "del ing\n",
    "for ing in ingredient_2:\n",
    "    ingredient_set.append(ing)\n",
    "del ing\n",
    "\n",
    "print(ingredient_set)\n",
    "\n",
    "#We need to shorten the ingredient_2 set\n",
    "\n",
    "with open(\"Ingredient_1.txt\", \"w\") as file:\n",
    "    for ing in ingredient_1:\n",
    "        file.write(ing)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "with open(\"Ingredient_2.txt\", \"w\") as file:\n",
    "    for ing in ingredient_2:\n",
    "        file.write(ing)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "with open(\"Overall_New.txt\", \"w\") as file:\n",
    "    for ing in ingredient_set:\n",
    "        file.write(ing)\n",
    "        file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Session Created\")\n",
    "#Python Java issues: a drawback in using pyspark instead of Scala"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spark.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- cook_time_minutes: long (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- error: boolean (nullable = true)\n",
      " |-- footnotes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- instructions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- photo_url: string (nullable = true)\n",
      " |-- prep_time_minutes: long (nullable = true)\n",
      " |-- rating_stars: double (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- time_scraped: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_time_minutes: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/centos/Desktop/ingest/allrecipes-recipes.json\"\n",
    "allrecipes_df = spark.read.json(path)\n",
    "allrecipes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- instructions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rating_stars: double (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- photo_url: string (nullable = true)\n",
      " |-- total_time_minutes: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+--------------------+\n",
      "|               title|         description|         ingredients|        instructions|rating_stars|review_count|           photo_url|total_time_minutes|                 url|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+--------------------+\n",
      "|Basil, Roasted Pe...|I just started ad...|[1/2 cup unsalted...|[Preheat oven to ...|        4.32|          46|http://images.med...|               100|http://allrecipes...|\n",
      "|Crispy Cheese Twists|These are great a...|[1/2 cup Parmesan...|[Combine parmesan...|        4.18|          44|http://images.med...|                 0|http://allrecipes...|\n",
      "|   Mom's Yeast Rolls|This is the best ...|[2 cups hot water...|[Melt margarine i...|        3.65|         168|http://images.med...|                 0|http://allrecipes...|\n",
      "|Sweet Potato Bread I|A Southern deligh...|[1 1/2 cups white...|[Combine sugar an...|         4.7|         344|http://images.med...|                 0|http://allrecipes...|\n",
      "|         Orange Buns|You can make thes...|[1/4 cup butter, ...|[Stir butter and ...|        4.71|           6|http://images.med...|               170|http://allrecipes...|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create temporary view to transform to dataframes\n",
    "allrecipes_df.createOrReplaceTempView(\"allrecipes\")\n",
    "\n",
    "#overall\n",
    "allrecipes_df = spark.sql(\"SELECT title, description, ingredients, instructions, rating_stars, review_count, photo_url, total_time_minutes, url FROM allrecipes LIMIT 1000\")\n",
    "allrecipes_df.printSchema()\n",
    "allrecipes_df.show(5)\n",
    "\n",
    "#to generate into sample\n",
    "# small_sample = allrecipes_df.toPandas()\n",
    "# small_sample.to_csv(\"small_sample.csv\")\n",
    "\n",
    "#Noted cook_time_minutes have quite a bit of zeroes. Use rating_stars and review_count instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['basil']\n",
      "UDF Successful.\n"
     ]
    }
   ],
   "source": [
    "#User-defined Functions\n",
    "def removeParenthesis(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "        text = text.strip()\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "def extractIngredient(li, ingredient_set):\n",
    "    output = []\n",
    "    for item in li:\n",
    "        temp_output = []\n",
    "        for set_tracker in range(len(ingredient_set)):\n",
    "            check = bool(re.search(ingredient_set[set_tracker], item))\n",
    "            if (check == True):    \n",
    "                temp_output.append(ingredient_set[set_tracker])\n",
    "        if (len(temp_output) != 0):\n",
    "#Comment\n",
    "#             temp_counter = 0\n",
    "#             temp_tracker = 0\n",
    "#             for temp in range(len(temp_output)):\n",
    "#                 count_temp = len(temp_output[temp])\n",
    "#                 if (count_temp > temp_counter):\n",
    "#                     temp_tracker = temp\n",
    "#                     temp_counter = count_temp\n",
    "#             output.append(temp_output[temp_tracker])\n",
    "#Comment\n",
    "            output.append(temp_output[[len(i) for i in temp_output].index(max([len(i) for i in temp_output]))])\n",
    "    return output\n",
    "\n",
    "sample = ['1/2 cup unsalted butter, chilled and cubed', '1 cup chopped onion', '1 3/4 cups cornmeal', '1 1/4 cups all-purpose flour', '1/4 cup white sugar', '1 tablespoon baking powder', '1 1/2 teaspoons salt', '1/2 teaspoon baking soda', '1 1/2 cups buttermilk', '3 eggs', '1 1/2 cups shredded pepperjack cheese', '1 1/3 cups frozen corn kernels, thawed and drained', '2 ounces roasted marinated red bell peppers, drained and chopped', '1/2 cup chopped fresh basil']\n",
    "\n",
    "test = extractIngredient(sample, ingredient_set)\n",
    "print(test)\n",
    "\n",
    "#create user defined function\n",
    "udf_removeParen = udf(removeParenthesis, ArrayType(StringType()))\n",
    "udf_extractIngredient = udf(lambda x: extractIngredient(x,ingredient_set), ArrayType(StringType()))\n",
    "udf_countList = udf(lambda x: len(x), IntegerType())\n",
    "\n",
    "print(\"UDF Successful.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Experimentation of creating shared matrix (TO BE DONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-------------+\n",
      "|               title|ingredient_extract|extract_count|\n",
      "+--------------------+------------------+-------------+\n",
      "|Basil, Roasted Pe...|           [basil]|            1|\n",
      "|Crispy Cheese Twists|                []|            0|\n",
      "|   Mom's Yeast Rolls|                []|            0|\n",
      "|Sweet Potato Bread I|                []|            0|\n",
      "|         Orange Buns|                []|            0|\n",
      "+--------------------+------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+----------+\n",
      "|              Recipe|Ingredient|\n",
      "+--------------------+----------+\n",
      "|Basil, Roasted Pe...|     basil|\n",
      "|Sun Dried Tomato ...|     basil|\n",
      "|Italian Herb Bread I|     basil|\n",
      "|     Cheddar Muffins|   paprika|\n",
      "|Whole Wheat Zucch...|     basil|\n",
      "|        Garlic Bread|     basil|\n",
      "|Garlic and Herb B...|     basil|\n",
      "|Tomato Basil Sher...|     basil|\n",
      "|            Fougasse|     basil|\n",
      "|   Cheese Herb Bread|     basil|\n",
      "|   Marron Layer Cake|    marron|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create ingredient table\n",
    "ingredient_df = allrecipes_df.select([\"title\", \"ingredients\"])\n",
    "cleanIngredient_df = ingredient_df.withColumn('rm_paren', udf_removeParen('ingredients')).select('title','ingredients','rm_paren') \\\n",
    "                         .withColumn('ingredient_extract', udf_extractIngredient('rm_paren')).select('title','ingredient_extract') \\\n",
    "                         .withColumn('extract_count', udf_countList('ingredient_extract')).select('title','ingredient_extract', 'extract_count')\n",
    "cleanIngredient_df.show(5)\n",
    "\n",
    "#to convert into graph form\n",
    "ingredient_graph = cleanIngredient_df.withColumn('exploded',explode('ingredient_extract')) \\\n",
    "                      .select(col('title').alias('Recipe'),col('exploded').alias('Ingredient'))\n",
    "#                       .withColumn(\"Frequency\", lit(1))\n",
    "ingredient_graph = ingredient_graph.filter(ingredient_graph.Ingredient != \"\")\n",
    "ingredient_graph.show(20)\n",
    "\n",
    "# graph_sample = ingredient_graph.toPandas()\n",
    "# graph_sample.to_csv(\"graph_sample.csv\")\n",
    "\n",
    "#Let's try convert ingredient into count_frequency (BAD WAY, don't do)\n",
    "# ingredient_freq = ingredient_graph.groupBy(\"Recipe\").pivot(\"Ingredient\").sum(\"Frequency\")\n",
    "# ingredient_freq.show()\n",
    "# test = ingredient_freq.toPandas()\n",
    "# test.to_csv(\"test.csv\")\n",
    "# print(\"test done\")\n",
    "\n",
    "\n",
    "#Proof of concept (Need to do !=)\n",
    "# print(ingredient_graph.filter(ingredient_graph.Ingredient.isNull()).count())\n",
    "# ingredient_graph = ingredient_graph.na.drop(subset=[\"Recipe\"])\n",
    "# test = ingredient_graph.filter(ingredient_graph.Recipe == \"Grandma Emma's Spice Loaf\")\n",
    "# test.show()\n",
    "# test2 = test.filter(ingredient_graph.Ingredient != \"\")\n",
    "# test2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------------+---------+-------+-------+\n",
      "|               title|ingredient_extract|vegetarian_label|nut_label|lactose|seafood|\n",
      "+--------------------+------------------+----------------+---------+-------+-------+\n",
      "|Basil, Roasted Pe...|           [basil]|               1|        0|      0|      0|\n",
      "|Crispy Cheese Twists|                []|               1|        0|      0|      0|\n",
      "|   Mom's Yeast Rolls|                []|               1|        0|      0|      0|\n",
      "|Sweet Potato Bread I|                []|               1|        0|      0|      0|\n",
      "|         Orange Buns|                []|               1|        0|      0|      0|\n",
      "+--------------------+------------------+----------------+---------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#User Defined Function - Feature Engineering \n",
    "#Labels: Vegetarian, Lactose, Nut, Seafood\n",
    "\n",
    "#Safer to start off as non-vegetarian\n",
    "def detectVege(li, vegDetect_list):\n",
    "    label = 0\n",
    "    detect_list = []\n",
    "    for text in li:\n",
    "        if text in vegDetect_list:\n",
    "            detect_list.append(text)\n",
    "    if (len(detect_list) == 0):\n",
    "        label = 1\n",
    "    return label\n",
    "\n",
    "#Safer to start off as positive allergy\n",
    "def detectNut(li):\n",
    "    label = 1\n",
    "    detect_list = []\n",
    "    for text in li:\n",
    "        if (\"nut\" in text):\n",
    "            detect_list.append(text)\n",
    "    if (len(detect_list) == 0):\n",
    "        label = 0\n",
    "    return label\n",
    "\n",
    "def detectDairy(li):\n",
    "    label = 1\n",
    "    dairy_list = [\"cheese\", \"milk\", \"yoghurt\", \"cream\"]\n",
    "    detect_list = []\n",
    "    for text in li:\n",
    "        if (text in dairy_list):\n",
    "            detect_list.append(text)\n",
    "    if (len(detect_list) == 0):\n",
    "        label = 0\n",
    "    return label\n",
    "\n",
    "def detectSeafood(li, seaDetect_list):\n",
    "    label = 1\n",
    "    detect_list = []\n",
    "    for text in li:\n",
    "        if text in seaDetect_list:\n",
    "            detect_list.append(text)\n",
    "    if (len(detect_list) == 0):\n",
    "        label = 0\n",
    "    return label\n",
    "\n",
    "\n",
    "with open(\"vegDetect.txt\", encoding=\"ISO-8859-1\") as veg_file:\n",
    "    vegDetect_list = veg_file.read().splitlines()\n",
    "\n",
    "with open(\"seafoodDetect.txt\", encoding=\"ISO-8859-1\") as seafood_file:\n",
    "    seaDetect_list = seafood_file.read().splitlines()\n",
    "    \n",
    "#create user defined function\n",
    "udf_detectVege = udf(lambda x: detectVege(x, vegDetect_list), IntegerType())\n",
    "udf_detectNut = udf(detectNut, IntegerType())\n",
    "udf_detectDairy = udf(detectDairy, IntegerType())\n",
    "udf_detectSeafood = udf(lambda x: detectSeafood(x, seaDetect_list), IntegerType())\n",
    "\n",
    "#experimentation of labelling\n",
    "labelling_df = cleanIngredient_df.select(\"title\", \"ingredient_extract\")\n",
    "labelling_df = labelling_df.withColumn(\"vegetarian_label\", udf_detectVege(\"ingredient_extract\")) \\\n",
    "                           .withColumn(\"nut_label\", udf_detectNut(\"ingredient_extract\")) \\\n",
    "                           .withColumn(\"lactose\", udf_detectDairy(\"ingredient_extract\")) \\\n",
    "                           .withColumn(\"seafood\", udf_detectSeafood(\"ingredient_extract\"))\n",
    "\n",
    "labelling_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = labelling_df.toPandas()\n",
    "# test.head()\n",
    "test.to_csv(\"test.csv\")\n",
    "# test = test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanIngredient_table = cleanIngredient_df.select(\"title\", \"rm_complete\")\n",
    "cleanIngredient_table = cleanIngredient_table.withColumn(\"Ing_Str\", udf_convertString(\"rm_complete\"))\n",
    "# cleanIngredient_table = cleanIngredient_table.withColumn(\"Ing_Str\", udf_convertString2(\"rm_complete\"))\n",
    "cleanIngredient_table = cleanIngredient_table.select(\"title\", col('Ing_Str').alias('Ingredient'))\n",
    "cleanIngredient_table = cleanIngredient_table.withColumn(\"ID\", monotonically_increasing_id())\n",
    "\n",
    "cleanIngredient_table.show(5)\n",
    "cleanIngredient_table.count()\n",
    "\n",
    "cleanIngredient_pandas = cleanIngredient_table.toPandas()\n",
    "cleanIngredient_pandas.to_csv(\"sample_clean.csv\")\n",
    "\n",
    "# cleanIngredient_table.createOrReplaceTempView('df')\n",
    "# cleanIngredient_table = spark.sql('select row_number() over (order by \"ID\") as num, * from df')\n",
    "# cleanIngredient_table.show(5)\n",
    "# cleanIngredient_table.count()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Ingredient\", outputCol=\"Component\")\n",
    "componentData = tokenizer.transform(cleanIngredient_table)\n",
    "hashingTF = HashingTF(inputCol=\"Component\", outputCol=\"Ing_Component\")\n",
    "featurizedData = hashingTF.transform(componentData)\n",
    "idf = IDF(inputCol=\"Ing_Component\", outputCol=\"Ing_Feature\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"Ing_Feature\", outputCol=\"norm\")\n",
    "similarity = normalizer.transform(rescaledData)\n",
    "sim_matrix = similarity.select(\"ID\", \"title\", \"norm\")\n",
    "sim_matrix.show()\n",
    "sim_test = sim_matrix.rdd.map(lambda row:IndexedRow(row.ID, row.norm.toArray()))\n",
    "type(sim_test)\n",
    "\n",
    "# mat = IndexedRowMatrix(similarity.select(\"title\", \"norm\")\\\n",
    "#                      .rdd.map(lambda row: IndexedRow(row.title, row.norm.toArray()))).toBlockMatrix()\n",
    "# dot = mat.multiply(mat.transpose())\n",
    "# dot.toLocalMatrix().toArray()\n",
    "\n",
    "# dot_udf = udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "# data.alias(\"i\").join(data.alias(\"j\"), col(\"i.title\") < col(\"j.title\"))\\\n",
    "#     .select(\n",
    "#         col(\"i.title\").alias(\"i\"), \n",
    "#         col(\"j.title\").alias(\"j\"), \n",
    "#         dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\"))\\\n",
    "#     .sort(\"i\", \"j\")\\\n",
    "#     .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = IndexedRowMatrix(sim_test).toBlockMatrix()\n",
    "dot = sim_mat.multiply(sim_mat.transpose())\n",
    "dot.toLocalMatrix().toArray()\n",
    "dot_udf = udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "\n",
    "similarity.alias(\"i\").join(similarity.alias(\"j\"), col(\"i.ID\") < col(\"j.ID\"))\\\n",
    "    .select(\n",
    "        col(\"i.ID\").alias(\"i\"), \n",
    "        col(\"j.ID\").alias(\"j\"), \n",
    "        dot_udf(\"i.ID\", \"j.ID\").alias(\"cosine\"))\\\n",
    "    .sort(\"i\", \"j\")\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv = CountVectorizer(inputCol=\"Ing_Str\", outputCol=\"Ing_Feature\", vocabSize=3, minDF=2.0)\n",
    "model = cv.fit(cleanIngredient_table)\n",
    "result = model.transform(cleanIngredient_table)\n",
    "result.show(5)\n",
    "test = result.toPandas()\n",
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Let's try create Graphs\n",
    "#Assuming user only wants recipe greater than 4 stars\n",
    "# user_request = allrecipes_df.filter(allrecipes_df.rating_stars > 4.0)\n",
    "user_request.show(5)\n",
    "#let's cache the user_request data\n",
    "# user_request.cache()\n",
    "# user_request.storageLevel\n",
    "# user_request.unpersist()\n",
    "# user_request.storageLevel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#let's try create a graph with the user_request data\n",
    "user_ingredient = user_request.select([\"title\", \"ingredients\"])\n",
    "user_cleanIngredient = user_ingredient.withColumn('rm_paren', udf_removeParen('ingredients')).select('title','ingredients','rm_paren') \\\n",
    "                         .withColumn('rm_after', udf_removeAfter('rm_paren')).select('title','ingredients','rm_paren','rm_after') \\\n",
    "                         .withColumn('rm_numbers', udf_removeNumbers('rm_after')).select('title','ingredients','rm_paren','rm_after','rm_numbers') \\\n",
    "                         .withColumn('rm_complete', udf_removeStop('rm_numbers')).select('title','ingredients','rm_paren','rm_after','rm_numbers','rm_complete')\n",
    "user_cleanIngredient.show(5)\n",
    "\n",
    "#to convert into graph form\n",
    "user_vertices = user_request.select([\"title\", \"rating_stars\", \"review_count\", \"total_time_minutes\"])\n",
    "\n",
    "user_edges = user_cleanIngredient.withColumn('exploded',explode('rm_complete')) \\\n",
    "                      .select(col('title').alias('Recipes'),col('exploded').alias('Ingredients')) \\\n",
    "                      .withColumn(\"Relationship\", lit(\"Contains\"))\n",
    "\n",
    "user_greater4 = user_edges.toPandas()\n",
    "user_greater4.to_csv(\"user_filtered.csv\")\n",
    "\n",
    "user_vertices.show(5)\n",
    "user_edges.show(5)\n",
    "\n",
    "user_graph = GraphFrame(user_vertices, user_edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Aggregated User-defined functions\n",
    "def removePara(text):\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "    return text\n",
    "def removeNum(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "def removePunc(text):\n",
    "    text = re.sub(r\"[//]\", \" \", text)\n",
    "    return text\n",
    "def removeComma(text):\n",
    "    text = re.sub(r\",[^,]*$\", \"\", text)\n",
    "    return text\n",
    "def removeStop(text, stoplist):\n",
    "    text_tok = text.split(\" \")\n",
    "    text_output = [tok for tok in text_tok if tok not in stoplist]\n",
    "    text_output = \" \".join(text_output)\n",
    "    return text_output\n",
    "\n",
    "def removeRules(li, stoplist):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = removePara(text)\n",
    "        text = removeNum(text)\n",
    "        text = removePunc(text)\n",
    "        text = removeComma(text)\n",
    "        text = text.strip()\n",
    "        text = removeStop(text, stoplist)\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "def removeRu2(li, stoplist as list):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "        text = re.sub(r\"\\d+\", \"\", text)\n",
    "        text = re.sub(r\"[//]\", \" \", text)\n",
    "        text = re.sub(r\",[^,]*$\", \"\", text)\n",
    "        text = text.strip()\n",
    "        text_tok = text.split(\" \")\n",
    "        text_output = [tok for tok in text_tok if tok not in stoplist]\n",
    "        text_output = \" \".join(text_output)\n",
    "        output.append(text_output)\n",
    "    return output\n",
    "\n",
    "sample = [\"1/2 cup unsalted butter, chilled and cubed\", \"1 cup chopped onion\", \"1 3/4 cups cornmeal\", \"1 1/4 cups all-purpose flour\", \"1/4 cup white sugar\", \"1 tablespoon baking powder\", \"1 1/2 teaspoons salt\", \"1/2 teaspoon baking soda\", \"1 1/2 cups buttermilk\", \"3 eggs\", \"1 1/2 cups shredded pepperjack cheese\", \"1 1/3 cups frozen corn kernels, thawed and drained\", \"2 ounces roasted marinated red bell peppers, drained and chopped\", \"1/2 cup chopped fresh basil\"]\n",
    "sample = removeRu2(sample, stopwords)\n",
    "print(sample)\n",
    "\n",
    "#create uder defined function\n",
    "udf_removeRules = udf(removeRules, ArrayType(StringType()))\n",
    "udf_removeRu2 = udf(removeRu2, ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create new column and test function\n",
    "#Spark Dataframes are immutable. Thus we have to create new columns\n",
    "test = ingredients_df.withColumn(\"New\", udf_removeRu2(ingredients_df[\"ingredients\"], stopwords))\n",
    "test.show(5)\n",
    "\n",
    "# test_pd = test.toPandas()\n",
    "# test_pd.head()\n",
    "# test_pd.to_csv(\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
