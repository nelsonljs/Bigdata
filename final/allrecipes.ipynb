{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark ran\n"
     ]
    }
   ],
   "source": [
    "from os import chdir\n",
    "from itertools import compress\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, explode, col, lit, monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, CountVectorizer\n",
    "from pyspark.mllib.linalg.distributed import IndexedRow, IndexedRowMatrix\n",
    "from graphframes import *\n",
    "import json\n",
    "import re\n",
    "import findspark\n",
    "findspark.init()\n",
    "print(\"spark ran\")\n",
    "\n",
    "chdir(\"C:\\\\Users\\\\chest\\\\Desktop\\\\MTech\\\\Big Data\\\\Project\\\\Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experimentation of stopwords\n",
    "stopwords=[\"packages\", \"ounces\", \"sheets\", \"sprig\", \"jars\",\\\n",
    "                  \"dashes\", \"ball\", \"jell\", \"tri\", \"grams\", \"shot\",\\\n",
    "                  \"cubes\", \"plastic\", \"jarred\", \"bunches\", \"prebaked\",\\\n",
    "                  \"can\", \"heads\", \"snickers\", \"bibb\", \"stemmed\", \"finely\",\\\n",
    "                  \"bunches\", \"trays\", \"spears\", \"free\", \"boston\", \"tablespoons\",\\\n",
    "                  \"pinches\", \"processed\", \"oz\", \"reynolds\", \"pouch\", \"bar\", \"carton\",\\\n",
    "                  \"solid\", \"inch\", \"inches\", \"cup\", \"cups\", \"gala\", \"thinly\", \"straight\",\\\n",
    "                  \"marinated\", \"drops\", \"one\", \"day\", \"buttery\", \"bing\", \"cube\", \"squeezes\",\\\n",
    "                  \"reduced\", \"double\", \"tubs\", \"bulbs\", \"sparkler\", \"scoop\", \"pint\", \"pouches\",\\\n",
    "                  \"long\", \"scoops\", \"shells\", \"comet\", \"shucked\", \"bars\", \"lean\", \"head\", \"hershey\",\\\n",
    "                  \"minature\", \"to\", \"hank\", \"cornish\", \"ear\", \"frilled\", \"curl\", \"frilled\", \"piece\",\\\n",
    "                  \"servings\", \"piece\", \"kaiser\", \"tenderflake\", \"dark\", \"servings\", \"quarts\", \"plain\",\\\n",
    "                  \"serving\", \"spiral\", \"skewers\", \"skewer\", \"navel\", \"quartered\", \"liter\", \"belgian\", \"bowl\",\\\n",
    "                  \"jigger\", \"o\", \"bottle\", \"portugese\", \"key\", \"foil\", \"thick\", \"roma\", \"birthday\", \"won\", \"slightly\",\\\n",
    "                  \"tablets\", \"raw\", \"bittersweet\", \"package\", \"jars\", \"weight\", \"teaspoons\", \"stalk\", \"unbaked\", \"feet\",\\\n",
    "                  \"mcintosh\", \"twist\", \"roasting\", \"canned\", \"tall\", \"recipes\", \"square\", \"sprigs\", \"slow\", \"envelopes\",\\\n",
    "                  \"warmed\", \"untreated\", \"ready\", \"archer\", \"inner\", \"packaged\", \"cans\", \"warm\", \"toothpick\", \"fresh\", \"fun\", \"bag\",\\\n",
    "                  \"hierloom\", \"bunch\", \"pkg\", \"strip\", \"unopened\", \"gallon\", \"ball\", \"skinned\", \"quart\", \"bouquet\", \"tubes\", \"vine\", \"sheet\",\\\n",
    "                  \"pieces\", \"splash\", \"container\", \"sliver\", \"purchased\", \"sliced\", \"racks\", \"half\", \"cubed\", \"wraps\", \"refrigerated\", \"sleeve\", \"london\",\\\n",
    "                  \"slices\", \"naval\", \"cleaned\", \"whisked\", \"pinch\", \"full\", \"sleeves\", \"pot\", \"metal\", \"sturdy\", \"muddled\", \"packets\", \"stalks\", \"prepared\", \"thin\",\\\n",
    "                  \"summer\", \"m\", \"large\", \"ring\", \"rolls\", \"box\", \"oven\", \"splashes\", \"plastic\", \"well\", \"loaves\", \"tiny\", \"sterilized\", \"market\", \"no\", \"sheets\", \"halves\", \"slice\", \"tablespoon\",\\\n",
    "                  \"slabs\", \"bricks\", \"pods\", \"gallons\", \"balls\", \"pre\", \"spot\", \"tub\", \"grilled\", \"torn\", \"canning\", \"slider\", \"brie\", \"cups\", \"or\", \"cubes\", \"pounds\", \"crumpets\", \"wedges\", \"crushed\", \"teaspoon\",\\\n",
    "                  \"individually\", \"sticks\", \"twists\", \"ears\", \"toothpicks\", \"links\", \"t\", \"cloves\", \"grinds\", \"trimmed\", \"drizzle\", \"tube\", \"shots\", \"organic\", \"boxes\", \"strips\", \"dash\", \"squirts\", \"diced\", \"beaten\", \"containers\", \"boneless\",\\\n",
    "                  \"skirt\", \"ounce\", \"hot\", \"unwrapped\", \"straw\", \"frozen\", \"roasted\", \"shredded\", \"dried\"] \n",
    "#stale, jet, worm, fillets, multi\n",
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "print(\"Spark Session Created\")\n",
    "#Python Java issues: a drawback in using pyspark instead of Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- cook_time_minutes: long (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- error: boolean (nullable = true)\n",
      " |-- footnotes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- instructions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- photo_url: string (nullable = true)\n",
      " |-- prep_time_minutes: long (nullable = true)\n",
      " |-- rating_stars: double (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- time_scraped: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- total_time_minutes: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\chest\\\\Desktop\\\\MTech\\\\Big Data\\\\Project\\\\Data\\\\allrecipes-recipes.json\"\n",
    "allrecipes_df = spark.read.json(path)\n",
    "allrecipes_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- ingredients: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- instructions: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rating_stars: double (nullable = true)\n",
      " |-- review_count: long (nullable = true)\n",
      " |-- photo_url: string (nullable = true)\n",
      " |-- total_time_minutes: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+\n",
      "|               title|         description|         ingredients|        instructions|rating_stars|review_count|           photo_url|total_time_minutes|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+\n",
      "|Basil, Roasted Pe...|I just started ad...|[1/2 cup unsalted...|[Preheat oven to ...|        4.32|          46|http://images.med...|               100|\n",
      "|Crispy Cheese Twists|These are great a...|[1/2 cup Parmesan...|[Combine parmesan...|        4.18|          44|http://images.med...|                 0|\n",
      "|   Mom's Yeast Rolls|This is the best ...|[2 cups hot water...|[Melt margarine i...|        3.65|         168|http://images.med...|                 0|\n",
      "|Sweet Potato Bread I|A Southern deligh...|[1 1/2 cups white...|[Combine sugar an...|         4.7|         344|http://images.med...|                 0|\n",
      "|         Orange Buns|You can make thes...|[1/4 cup butter, ...|[Stir butter and ...|        4.71|           6|http://images.med...|               170|\n",
      "+--------------------+--------------------+--------------------+--------------------+------------+------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create temporary view to transform to dataframes\n",
    "allrecipes_df.createOrReplaceTempView(\"allrecipes\")\n",
    "\n",
    "#overall\n",
    "allrecipes_df = spark.sql(\"SELECT title, description, ingredients, instructions, rating_stars, review_count, photo_url, total_time_minutes FROM allrecipes LIMIT 5000\")\n",
    "allrecipes_df.printSchema()\n",
    "allrecipes_df.show(5)\n",
    "\n",
    "#to generate into sample\n",
    "# small_sample = allrecipes_df.toPandas()\n",
    "# small_sample.to_csv(\"small_sample.csv\")\n",
    "\n",
    "#Noted cook_time_minutes have quite a bit of zeroes. Use rating_stars and review_count instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDF Successful.\n"
     ]
    }
   ],
   "source": [
    "#User-defined Functions\n",
    "def removeParenthesis(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "        text = text.strip()\n",
    "        output.append(text)\n",
    "    return output\n",
    "def removeNumbers(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\"\\d+\", \"\", text)\n",
    "        text = re.sub(r\"[//]\", \" \", text)\n",
    "        text = text.strip()\n",
    "        output.append(text)\n",
    "    return output\n",
    "def removeAfterComma(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\",[^,]*$\", \"\", text)\n",
    "        text = text.strip()\n",
    "        output.append(text)\n",
    "    return output\n",
    "def removeStop(li, stoplist):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text_tok = text.split(\" \")\n",
    "        text_output = [tok for tok in text_tok if tok not in stoplist]\n",
    "        text_output = \" \".join(text_output)\n",
    "        output.append(text_output)\n",
    "    return output\n",
    "\n",
    "def convertString(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text_combined = text.replace(\" \", \"-\")\n",
    "        output.append(text_combined)\n",
    "    output_transformed = \" \".join(output)\n",
    "    return output_transformed\n",
    "\n",
    "def convertString2(li):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text_combined = text.replace(\" \", \"-\")\n",
    "        output.append(text_combined)\n",
    "    return output\n",
    "\n",
    "#create user defined function\n",
    "udf_removeAfter = udf(removeAfterComma, ArrayType(StringType()))\n",
    "udf_removeParen = udf(removeParenthesis, ArrayType(StringType()))\n",
    "udf_removeNumbers = udf(removeNumbers, ArrayType(StringType()))\n",
    "udf_removeStop = udf(lambda x: removeStop(x,stopwords), ArrayType(StringType()))\n",
    "udf_convertString = udf(convertString, StringType())\n",
    "udf_convertString2 = udf(convertString2, ArrayType(StringType()))\n",
    "\n",
    "print(\"UDF Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Defined Function - Feature Engineering \n",
    "def detectVege(li, veg_list):\n",
    "    label = []\n",
    "    for text in li:\n",
    "        if text not in veg_list:\n",
    "            label.append(text)\n",
    "            label.append(\"Veg\")\n",
    "    return label\n",
    "\n",
    "#create user defined function\n",
    "udf_detectVege = udf(lambda x: detectVege(x, veg_list), ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               title|         ingredients|            rm_paren|            rm_after|          rm_numbers|         rm_complete|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Basil, Roasted Pe...|[1/2 cup unsalted...|[1/2 cup unsalted...|[1/2 cup unsalted...|[cup unsalted but...|[unsalted butter,...|\n",
      "|Crispy Cheese Twists|[1/2 cup Parmesan...|[1/2 cup Parmesan...|[1/2 cup Parmesan...|[cup Parmesan che...|[Parmesan cheese,...|\n",
      "|   Mom's Yeast Rolls|[2 cups hot water...|[2 cups hot water...|[2 cups hot water...|[cups hot water, ...|[water, margarine...|\n",
      "|Sweet Potato Bread I|[1 1/2 cups white...|[1 1/2 cups white...|[1 1/2 cups white...|[cups white sugar...|[white sugar, veg...|\n",
      "|         Orange Buns|[1/4 cup butter, ...|[1/4 cup butter, ...|[1/4 cup butter, ...|[cup butter, teas...|[butter, white su...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----------------+---------+\n",
      "|              Recipe|       Ingredient|Frequency|\n",
      "+--------------------+-----------------+---------+\n",
      "|Basil, Roasted Pe...|  unsalted butter|        1|\n",
      "|Basil, Roasted Pe...|    chopped onion|        1|\n",
      "|Basil, Roasted Pe...|         cornmeal|        1|\n",
      "|Basil, Roasted Pe...|all-purpose flour|        1|\n",
      "|Basil, Roasted Pe...|      white sugar|        1|\n",
      "+--------------------+-----------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create ingredient table\n",
    "ingredient_df = allrecipes_df.select([\"title\", \"ingredients\"])\n",
    "cleanIngredient_df = ingredient_df.withColumn('rm_paren', udf_removeParen('ingredients')).select('title','ingredients','rm_paren') \\\n",
    "                         .withColumn('rm_after', udf_removeAfter('rm_paren')).select('title','ingredients','rm_paren','rm_after') \\\n",
    "                         .withColumn('rm_numbers', udf_removeNumbers('rm_after')).select('title','ingredients','rm_paren','rm_after','rm_numbers') \\\n",
    "                         .withColumn('rm_complete', udf_removeStop('rm_numbers')).select('title','ingredients','rm_paren','rm_after','rm_numbers','rm_complete')\n",
    "cleanIngredient_df.show(5)\n",
    "\n",
    "#to convert into graph form\n",
    "ingredient_graph = cleanIngredient_df.withColumn('exploded',explode('rm_complete')) \\\n",
    "                      .select(col('title').alias('Recipe'),col('exploded').alias('Ingredient'))\\\n",
    "                      .withColumn(\"Frequency\", lit(1))\n",
    "ingredient_graph = ingredient_graph.filter(ingredient_graph.Ingredient != \"\")\n",
    "ingredient_graph.show(5)\n",
    "#Let's try convert ingredient into count_frequency (BAD WAY, don't do)\n",
    "# ingredient_freq = ingredient_graph.groupBy(\"Recipe\").pivot(\"Ingredient\").sum(\"Frequency\")\n",
    "# ingredient_freq.show()\n",
    "# test = ingredient_freq.toPandas()\n",
    "# test.to_csv(\"test.csv\")\n",
    "# print(\"test done\")\n",
    "\n",
    "\n",
    "#Proof of concept (Need to do !=)\n",
    "# print(ingredient_graph.filter(ingredient_graph.Ingredient.isNull()).count())\n",
    "# ingredient_graph = ingredient_graph.na.drop(subset=[\"Recipe\"])\n",
    "# test = ingredient_graph.filter(ingredient_graph.Recipe == \"Grandma Emma's Spice Loaf\")\n",
    "# test.show()\n",
    "# test2 = test.filter(ingredient_graph.Ingredient != \"\")\n",
    "# test2.show()\n",
    "\n",
    "# graph_sample = ingredient_graph.toPandas()\n",
    "# graph_sample.to_csv(\"graph_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vegetarian.txt\") as veg_file:\n",
    "    veg_list = veg_file.read().splitlines()\n",
    "print(veg_list)\n",
    "\n",
    "test = allrecipes_df.withColumn(\"veg_label\", udf_detectVege(\"ingredients\"))\n",
    "test = test.select(\"ingredients\", \"veg_label\")\n",
    "test.show(5)\n",
    "\n",
    "# test_veg = test.filter(test.veg_label != \"\")\n",
    "# test_veg.show(5)\n",
    "# veg_pandas = test_veg.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+\n",
      "|               title|          Ingredient| ID|\n",
      "+--------------------+--------------------+---+\n",
      "|Basil, Roasted Pe...|unsalted-butter c...|  0|\n",
      "|Crispy Cheese Twists|Parmesan-cheese g...|  1|\n",
      "|   Mom's Yeast Rolls|water margarine w...|  2|\n",
      "|Sweet Potato Bread I|white-sugar veget...|  3|\n",
      "|         Orange Buns|butter white-suga...|  4|\n",
      "+--------------------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanIngredient_table = cleanIngredient_df.select(\"title\", \"rm_complete\")\n",
    "cleanIngredient_table = cleanIngredient_table.withColumn(\"Ing_Str\", udf_convertString(\"rm_complete\"))\n",
    "# cleanIngredient_table = cleanIngredient_table.withColumn(\"Ing_Str\", udf_convertString2(\"rm_complete\"))\n",
    "cleanIngredient_table = cleanIngredient_table.select(\"title\", col('Ing_Str').alias('Ingredient'))\n",
    "cleanIngredient_table = cleanIngredient_table.withColumn(\"ID\", monotonically_increasing_id())\n",
    "\n",
    "cleanIngredient_table.show(5)\n",
    "cleanIngredient_table.count()\n",
    "\n",
    "cleanIngredient_pandas = cleanIngredient_table.toPandas()\n",
    "cleanIngredient_pandas.to_csv(\"sample_clean.csv\")\n",
    "\n",
    "# cleanIngredient_table.createOrReplaceTempView('df')\n",
    "# cleanIngredient_table = spark.sql('select row_number() over (order by \"ID\") as num, * from df')\n",
    "# cleanIngredient_table.show(5)\n",
    "# cleanIngredient_table.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:51636)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\", line 929, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\", line 1067, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:51636)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-db700f71e197>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Ingredient\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Component\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcomponentData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleanIngredient_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhashingTF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHashingTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Component\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Ing_Component\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfeaturizedData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhashingTF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponentData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0midf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Ing_Component\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Ing_Feature\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Method %s forces keyword arguments.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\ml\\feature.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputCol, outputCol)\u001b[0m\n\u001b[0;32m   2717\u001b[0m         \"\"\"\n\u001b[0;32m   2718\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2719\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_java_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"org.apache.spark.ml.feature.Tokenizer\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2720\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[1;34m(java_class, *args)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mjava_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_jvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjava_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mjava_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1647\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFLECTION_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREFL_GET_UNKNOWN_SUB_COMMAND_NAME\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m             \"\\n\" + proto.END_COMMAND_PART)\n\u001b[0m\u001b[0;32m   1650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS_PACKAGE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mJavaPackage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway_client\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjvm_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    981\u001b[0m          \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \"\"\"\n\u001b[1;32m--> 983\u001b[1;33m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    929\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         connection = GatewayConnection(\n\u001b[0;32m    936\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[1;32m--> 937\u001b[1;33m         \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chest\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1077\u001b[0m                 \u001b[1;34m\"server ({0}:{1})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:51636)"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Ingredient\", outputCol=\"Component\")\n",
    "componentData = tokenizer.transform(cleanIngredient_table)\n",
    "hashingTF = HashingTF(inputCol=\"Component\", outputCol=\"Ing_Component\")\n",
    "featurizedData = hashingTF.transform(componentData)\n",
    "idf = IDF(inputCol=\"Ing_Component\", outputCol=\"Ing_Feature\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"Ing_Feature\", outputCol=\"norm\")\n",
    "similarity = normalizer.transform(rescaledData)\n",
    "sim_matrix = similarity.select(\"ID\", \"title\", \"norm\")\n",
    "sim_matrix.show()\n",
    "sim_test = sim_matrix.rdd.map(lambda row:IndexedRow(row.ID, row.norm.toArray()))\n",
    "type(sim_test)\n",
    "\n",
    "# mat = IndexedRowMatrix(similarity.select(\"title\", \"norm\")\\\n",
    "#                      .rdd.map(lambda row: IndexedRow(row.title, row.norm.toArray()))).toBlockMatrix()\n",
    "# dot = mat.multiply(mat.transpose())\n",
    "# dot.toLocalMatrix().toArray()\n",
    "\n",
    "# dot_udf = udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "# data.alias(\"i\").join(data.alias(\"j\"), col(\"i.title\") < col(\"j.title\"))\\\n",
    "#     .select(\n",
    "#         col(\"i.title\").alias(\"i\"), \n",
    "#         col(\"j.title\").alias(\"j\"), \n",
    "#         dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\"))\\\n",
    "#     .sort(\"i\", \"j\")\\\n",
    "#     .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat = IndexedRowMatrix(sim_test).toBlockMatrix()\n",
    "dot = sim_mat.multiply(sim_mat.transpose())\n",
    "dot.toLocalMatrix().toArray()\n",
    "dot_udf = udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
    "\n",
    "similarity.alias(\"i\").join(similarity.alias(\"j\"), col(\"i.ID\") < col(\"j.ID\"))\\\n",
    "    .select(\n",
    "        col(\"i.ID\").alias(\"i\"), \n",
    "        col(\"j.ID\").alias(\"j\"), \n",
    "        dot_udf(\"i.ID\", \"j.ID\").alias(\"cosine\"))\\\n",
    "    .sort(\"i\", \"j\")\\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv = CountVectorizer(inputCol=\"Ing_Str\", outputCol=\"Ing_Feature\", vocabSize=3, minDF=2.0)\n",
    "model = cv.fit(cleanIngredient_table)\n",
    "result = model.transform(cleanIngredient_table)\n",
    "result.show(5)\n",
    "test = result.toPandas()\n",
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Let's try create Graphs\n",
    "#Assuming user only wants recipe greater than 4 stars\n",
    "# user_request = allrecipes_df.filter(allrecipes_df.rating_stars > 4.0)\n",
    "user_request.show(5)\n",
    "#let's cache the user_request data\n",
    "# user_request.cache()\n",
    "# user_request.storageLevel\n",
    "# user_request.unpersist()\n",
    "# user_request.storageLevel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#let's try create a graph with the user_request data\n",
    "user_ingredient = user_request.select([\"title\", \"ingredients\"])\n",
    "user_cleanIngredient = user_ingredient.withColumn('rm_paren', udf_removeParen('ingredients')).select('title','ingredients','rm_paren') \\\n",
    "                         .withColumn('rm_after', udf_removeAfter('rm_paren')).select('title','ingredients','rm_paren','rm_after') \\\n",
    "                         .withColumn('rm_numbers', udf_removeNumbers('rm_after')).select('title','ingredients','rm_paren','rm_after','rm_numbers') \\\n",
    "                         .withColumn('rm_complete', udf_removeStop('rm_numbers')).select('title','ingredients','rm_paren','rm_after','rm_numbers','rm_complete')\n",
    "user_cleanIngredient.show(5)\n",
    "\n",
    "#to convert into graph form\n",
    "user_vertices = user_request.select([\"title\", \"rating_stars\", \"review_count\", \"total_time_minutes\"])\n",
    "\n",
    "user_edges = user_cleanIngredient.withColumn('exploded',explode('rm_complete')) \\\n",
    "                      .select(col('title').alias('Recipes'),col('exploded').alias('Ingredients')) \\\n",
    "                      .withColumn(\"Relationship\", lit(\"Contains\"))\n",
    "\n",
    "user_greater4 = user_edges.toPandas()\n",
    "user_greater4.to_csv(\"user_filtered.csv\")\n",
    "\n",
    "user_vertices.show(5)\n",
    "user_edges.show(5)\n",
    "\n",
    "user_graph = GraphFrame(user_vertices, user_edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Aggregated User-defined functions\n",
    "def removePara(text):\n",
    "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "    return text\n",
    "def removeNum(text):\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    return text\n",
    "def removePunc(text):\n",
    "    text = re.sub(r\"[//]\", \" \", text)\n",
    "    return text\n",
    "def removeComma(text):\n",
    "    text = re.sub(r\",[^,]*$\", \"\", text)\n",
    "    return text\n",
    "def removeStop(text, stoplist):\n",
    "    text_tok = text.split(\" \")\n",
    "    text_output = [tok for tok in text_tok if tok not in stoplist]\n",
    "    text_output = \" \".join(text_output)\n",
    "    return text_output\n",
    "\n",
    "def removeRules(li, stoplist):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = removePara(text)\n",
    "        text = removeNum(text)\n",
    "        text = removePunc(text)\n",
    "        text = removeComma(text)\n",
    "        text = text.strip()\n",
    "        text = removeStop(text, stoplist)\n",
    "        output.append(text)\n",
    "    return output\n",
    "\n",
    "def removeRu2(li, stoplist as list):\n",
    "    output = []\n",
    "    for text in li:\n",
    "        text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
    "        text = re.sub(r\"\\d+\", \"\", text)\n",
    "        text = re.sub(r\"[//]\", \" \", text)\n",
    "        text = re.sub(r\",[^,]*$\", \"\", text)\n",
    "        text = text.strip()\n",
    "        text_tok = text.split(\" \")\n",
    "        text_output = [tok for tok in text_tok if tok not in stoplist]\n",
    "        text_output = \" \".join(text_output)\n",
    "        output.append(text_output)\n",
    "    return output\n",
    "\n",
    "sample = [\"1/2 cup unsalted butter, chilled and cubed\", \"1 cup chopped onion\", \"1 3/4 cups cornmeal\", \"1 1/4 cups all-purpose flour\", \"1/4 cup white sugar\", \"1 tablespoon baking powder\", \"1 1/2 teaspoons salt\", \"1/2 teaspoon baking soda\", \"1 1/2 cups buttermilk\", \"3 eggs\", \"1 1/2 cups shredded pepperjack cheese\", \"1 1/3 cups frozen corn kernels, thawed and drained\", \"2 ounces roasted marinated red bell peppers, drained and chopped\", \"1/2 cup chopped fresh basil\"]\n",
    "sample = removeRu2(sample, stopwords)\n",
    "print(sample)\n",
    "\n",
    "#create uder defined function\n",
    "udf_removeRules = udf(removeRules, ArrayType(StringType()))\n",
    "udf_removeRu2 = udf(removeRu2, ArrayType(StringType()))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create new column and test function\n",
    "#Spark Dataframes are immutable. Thus we have to create new columns\n",
    "test = ingredients_df.withColumn(\"New\", udf_removeRu2(ingredients_df[\"ingredients\"], stopwords))\n",
    "test.show(5)\n",
    "\n",
    "# test_pd = test.toPandas()\n",
    "# test_pd.head()\n",
    "# test_pd.to_csv(\"test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
